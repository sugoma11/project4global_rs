{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim import AdamW\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import ResNet\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision.models.resnet import ResNet\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.data import *\n",
    "from utils.log import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Wandb logging and setup from config  \n",
    "1.1 - Sort of builder from cfg\n",
    "2 - Dataloader with slicing  \n",
    "3 - Define some models  \n",
    "4 - Wrap it into slurm tasks and add saving of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock1x1(nn.Module):\n",
    "    \"\"\"Basic Resnet block but instead of 3x3 convs we use 1x1 convs\"\"\"\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self,\n",
    "                 inplanes,\n",
    "                 planes,\n",
    "                 stride = 1,\n",
    "                 downsample = None,\n",
    "                 groups = 1,\n",
    "                 base_width = 64,\n",
    "                 dilation = 1,\n",
    "                 norm_layer = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv1x1(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s1, y_train_s1, full_distrib_train_s1, X_val_s1, y_val_s1, full_distrib_val_s1 = load_pickled_ds('data/pickled_data/raw_train_test_splitted_s1_60.pkl')\n",
    "X_train_s2, y_train_s2, full_distrib_train_s2, X_val_s2, y_val_s2, full_distrib_val_s2 = load_pickled_ds('data/pickled_data/raw_train_test_splitted_s2_60.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_order_s2 = [\"B02\", \"B03\", \"B04\", \"B08\", \"B05\", \"B06\", \"B07\", \"B08A\", \"B11\", \"B12\", \"B01\", \"B09\"]\n",
    "channel_order_s1 = [\"VV\", \"VH\", \"VV/VH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "bs = 512\n",
    "\n",
    "ri = [\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B08A\", \"B09\", \"B11\", \"B12\", \"NDVI\", \"EVI\", \"NDWI\", \"GNDVI\", \"SAVI\", \"ARVI\", \"MSAVI\"]\n",
    "\n",
    "train_dataset_s1 = NumpyDataset(X_train_s1, y_train_s1, sentinel_number=1, band_order=channel_order_s1, requested_indices=[\"VV\", \"VH\", \"VV/VH\"])\n",
    "train_dataset_s2 = NumpyDataset(X_train_s2, y_train_s2, sentinel_number=2, band_order=channel_order_s2,\n",
    "                                requested_indices=ri)\n",
    "\n",
    "\n",
    "val_dataset_s1 = NumpyDataset(X_val_s1, y_val_s1, sentinel_number=1, band_order=channel_order_s1, requested_indices=[\"VV\", \"VH\", \"VV/VH\"])\n",
    "val_dataset_s2 = NumpyDataset(X_val_s2, y_val_s2, sentinel_number=2, band_order=channel_order_s2, \n",
    "                              requested_indices=ri)\n",
    "\n",
    "\n",
    "train_dataloader_s1 = DataLoader(train_dataset_s1, batch_size=bs, shuffle=True, generator=g)\n",
    "train_dataloader_s2 = DataLoader(train_dataset_s2, batch_size=bs, shuffle=True, generator=g)\n",
    "\n",
    "val_dataloader_s1 = DataLoader(val_dataset_s1, batch_size=bs, shuffle=True, generator=g)\n",
    "val_dataloader_s2 = DataLoader(val_dataset_s2, batch_size=bs, shuffle=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'models.cnns' from '/home/al/projects/global_rs_project/models/cnns.py'> Resnet1x1TwoLayers\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m m \u001b[38;5;241m=\u001b[39m get_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcnns.Resnet1x1TwoLayers\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_bands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m m\u001b[38;5;241m.\u001b[39mforward(torch\u001b[38;5;241m.\u001b[39mrandn(size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m)))\n",
      "File \u001b[0;32m~/projects/global_rs_project/models/cnns.py:96\u001b[0m, in \u001b[0;36mResnet1x1TwoLayers.__init__\u001b[0;34m(self, n_classes, n_bands, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     90\u001b[0m              n_classes, \n\u001b[1;32m     91\u001b[0m              n_bands,\n\u001b[1;32m     92\u001b[0m              \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m     93\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     94\u001b[0m             ):\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBasicBlock1x1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_bands \u001b[38;5;241m=\u001b[39m n_bands\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(n_bands, \n\u001b[1;32m    101\u001b[0m                                   \u001b[38;5;241m64\u001b[39m, \n\u001b[1;32m    102\u001b[0m                                   kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[1;32m    103\u001b[0m                                   stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m    104\u001b[0m                                   padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m    105\u001b[0m                                   bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/envs/torch/lib/python3.10/site-packages/torchvision/models/resnet.py:203\u001b[0m, in \u001b[0;36mResNet.__init__\u001b[0;34m(self, block, layers, num_classes, zero_init_residual, groups, width_per_group, replace_stride_with_dilation, norm_layer)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_layer(block, \u001b[38;5;241m64\u001b[39m, layers[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_layer(block, \u001b[38;5;241m128\u001b[39m, layers[\u001b[38;5;241m1\u001b[39m], stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dilate\u001b[38;5;241m=\u001b[39mreplace_stride_with_dilation[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_layer(block, \u001b[38;5;241m256\u001b[39m, \u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dilate\u001b[38;5;241m=\u001b[39mreplace_stride_with_dilation[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_layer(block, \u001b[38;5;241m512\u001b[39m, layers[\u001b[38;5;241m3\u001b[39m], stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dilate\u001b[38;5;241m=\u001b[39mreplace_stride_with_dilation[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mAdaptiveAvgPool2d((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from models import get_model\n",
    "import torch\n",
    "\n",
    "m = get_model('cnns.Resnet1x1TwoLayers')\n",
    "m = m(n_bands=3, n_classes=15)\n",
    "\n",
    "m.forward(torch.randn(size=(100, 3, 6, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 1.9796, Accuracy: 37.52%\n",
      "Validation Loss: 1.8448, Accuracy: 40.96%\n",
      "Epoch [2/3], Loss: 1.7384, Accuracy: 44.18%\n",
      "Validation Loss: 1.7633, Accuracy: 42.74%\n",
      "Epoch [3/3], Loss: 1.6556, Accuracy: 46.54%\n",
      "Validation Loss: 1.7248, Accuracy: 43.89%\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils.models import Resnet1x1, MLP\n",
    "\n",
    "ce = CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sample = next(iter(train_dataloader_s2))[0]\n",
    "n_bands = sample.shape[1]\n",
    "input_size = sample.shape[2]\n",
    "\n",
    "rs = Resnet1x1(n_classes=15, n_bands=n_bands, input_size=input_size)\n",
    "rs.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.AdamW(rs.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "num_epochs = 3  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    rs.train() \n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, _, labels in train_dataloader_s2:\n",
    "        inputs, labels = inputs.to(device, dtype=torch.float), labels.to(device, dtype=torch.long)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = rs.forward(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_dataloader_s2):.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation loop\n",
    "    rs.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # No gradient calculation during validation\n",
    "        for inputs, _, labels in val_dataloader_s2:\n",
    "            inputs, labels = inputs.to(device, dtype=torch.float), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = rs(inputs)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Statistics\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Loss: {val_loss/len(val_dataloader_s2):.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_loader, val_loader, lr, weight_decay, loss_fn, metric_fn,\n",
    "                       device, num_epochs, step2decay, decay_lr):\n",
    "    \n",
    "    \n",
    "    indiced_sample, raw_sample = next(iter(train_loader))[:2]\n",
    "    n_bands_raw, n_bands_indices = indiced_sample.shape[1], raw_sample.shape[1]\n",
    "\n",
    "    rs_indiced = Resnet1x1(n_classes=15, n_bands=n_bands_indices)\n",
    "    rs_raw = Resnet1x1(n_classes=15, n_bands=n_bands_raw)\n",
    "\n",
    "    rs_indiced.model.to(device)\n",
    "    rs_raw.model.to(device)\n",
    "\n",
    "    loss_fn_raw = loss_fn().to(device)\n",
    "    loss_fn_indiced = loss_fn().to(device)\n",
    "\n",
    "\n",
    "    optimizer_raw = optim.AdamW(rs_raw.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    optimizer_indiced = optim.AdamW(rs_indiced.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    scheduler_raw = StepLR(optimizer_raw, step_size=step2decay, gamma=decay_lr)\n",
    "    scheduler_indiced = StepLR(optimizer_indiced, step_size=step2decay, gamma=decay_lr)\n",
    "\n",
    "\n",
    "    iter_log = IterLog()\n",
    "    train_log = TrainLog()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        iter_log.on_iter_start()\n",
    "\n",
    "        rs_indiced.model.train() \n",
    "        rs_raw.model.train() \n",
    "\n",
    "\n",
    "        for inputs_raw, inputs_indiced, labels in train_loader:\n",
    "            inputs_raw, inputs_indiced, labels = inputs_raw.to(device, dtype=torch.float), inputs_indiced.to(device, dtype=torch.float), labels.to(device, dtype=torch.long)\n",
    "\n",
    "            optimizer_raw.zero_grad()\n",
    "            optimizer_indiced.zero_grad()\n",
    "\n",
    "            outputs_raw = rs_raw.forward(inputs_raw)\n",
    "            outputs_indiced = rs_indiced.forward(inputs_indiced)\n",
    "\n",
    "            loss_raw = loss_fn_raw(outputs_raw, labels)\n",
    "            loss_raw.backward()\n",
    "\n",
    "            loss_indiced = loss_fn_indiced(outputs_indiced, labels)\n",
    "            loss_indiced.backward()\n",
    "\n",
    "            optimizer_raw.step()\n",
    "            optimizer_indiced.step()\n",
    "\n",
    "            scheduler_raw.step()\n",
    "            scheduler_indiced.step()\n",
    "\n",
    "            _, predicted_raw = torch.max(outputs_raw, 1)\n",
    "            _, predicted_indiced = torch.max(outputs_indiced, 1)\n",
    "\n",
    "            metric_raw = metric_fn(predicted_raw, labels)\n",
    "            metric_indiced = metric_fn(predicted_indiced, labels)\n",
    "\n",
    "            iter_log.add_on_train_iter_end(train_loss_indiced=loss_indiced.item(), train_loss_raw=loss_raw.item(),\n",
    "                                           train_metric_raw=metric_raw.item(), train_metric_indiced=metric_indiced.item())\n",
    "\n",
    "        rs_raw.model.eval()\n",
    "        rs_indiced.model.eval()\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            for inputs_raw, inputs_indiced, labels in val_loader:\n",
    "                inputs_raw, inputs_indiced, labels = inputs_raw.to(device, dtype=torch.float), inputs_indiced.to(device, dtype=torch.float), labels.to(device, dtype=torch.long)\n",
    "\n",
    "                outputs_raw = rs_raw.forward(inputs_raw)\n",
    "                outputs_indiced = rs_indiced.forward(inputs_indiced)\n",
    "\n",
    "                loss_raw = loss_fn_raw(outputs_raw, labels)\n",
    "                loss_indiced = loss_fn_indiced(outputs_indiced, labels)\n",
    "\n",
    "                _, predicted_raw = torch.max(outputs_raw, 1)\n",
    "                _, predicted_indiced = torch.max(outputs_indiced, 1)\n",
    "                \n",
    "                metric_raw = metric_fn(predicted_raw, labels)\n",
    "                metric_indiced = metric_fn(predicted_indiced, labels)\n",
    "\n",
    "                iter_log.add_on_val_iter_end(val_loss_indiced=loss_indiced.item(), val_loss_raw=loss_raw.item(),\n",
    "                                             val_metric_raw=metric_raw.item(), val_metric_indiced=metric_indiced.item())\n",
    "\n",
    "        iter_log.on_epoch_end()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], {iter_log}\")\n",
    "\n",
    "        train_log.on_epoch_end(iter_log)\n",
    "\n",
    "    train_log.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, gt):\n",
    "    return (pred == gt).sum() / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_and_evaluate() got multiple values for argument 'step2decay'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader_s2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader_s2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep2decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: train_and_evaluate() got multiple values for argument 'step2decay'"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(train_dataloader_s2, val_dataloader_s2, 0.001, 0.0001, CrossEntropyLoss, accuracy, 'cuda:0', 40, 'test', step2decay=15, decay_lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_loader, val_loader, lr, weight_decay, loss_fn, metric_fn,\n",
    "                       device, num_epochs, experiment_name, scheduler):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
